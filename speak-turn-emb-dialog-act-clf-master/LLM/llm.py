# -*- coding: utf-8 -*-
"""LLM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1UvrcKozzX7H1sjkE_YY1y1PJopiyaBzI
"""

!pip install openai datasets

!pip install openai==0.28

!pip install --upgrade openai datasets fsspec==2025.3.0

!pip install "torch==2.5.0" "nvidia-cudnn-cu12==9.1.0.70" "fsspec==2025.3.2" "gcsfs==2025.3.2"

import openai
from datasets import load_dataset
import random



openai.api_key ="OPEN AI KEY"

def create_prompt(examples, test_utterance):
    prompt = "Classify the dialogue act of each utterance.\n\n"
    for ex in examples:
        prompt += f"Utterance: {ex['text']}\nDialogue Act: {ex['act']}\n\n"
    prompt += f"Utterance: {test_utterance}\nDialogue Act:"
    return prompt

def gpt3_predict(prompt):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
            max_tokens=10
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        print("⚠️ OpenAI API Error:", e)
        return "ERROR"

def load_json_dataset(dataset_name):
    import requests
    import json

    base_url = f"https://raw.githubusercontent.com/zihaohe123/speak-turn-emb-dialog-act-clf/master/data/{dataset_name}"
    train_url = f"{base_url}/train.json"
    test_url = f"{base_url}/test.json"

    def load_json_lines(url):
        response = requests.get(url)
        lines = response.text.strip().split('\n')
        return [json.loads(line) for line in lines if line.strip()]

    train_data = load_json_lines(train_url)
    test_data = load_json_lines(test_url)

    return train_data, test_data


def evaluate_dataset(dataset_name, k=5, test_samples=10):
    print(f"\n=== Evaluating {dataset_name.upper()} ===")
    train_data, test_data = load_json_dataset(dataset_name)
    random.seed(42)
    correct = 0

    for i in range(test_samples):
        few_shot_examples = random.sample(train_data, k)
        test_example = test_data[i]
        prompt = create_prompt(few_shot_examples, test_example['text'])
        prediction = gpt3_predict(prompt)
        print(f"[{i+1}] Predicted: {prediction} | Actual: {test_example['act']}")
        if prediction.lower().strip() == test_example['act'].lower().strip():
            correct += 1

    accuracy = correct / test_samples
    print(f"\n✅ Accuracy on {test_samples} samples from {dataset_name.upper()}: {accuracy:.2f}")

def create_prompt(examples, test_utterance):
    prompt = "Classify the dialogue act of each utterance.\n\n"
    for ex in examples:
        prompt += f"Utterance: {ex['text']}\nDialogue Act: {ex['act']}\n\n"
    prompt += f"Utterance: {test_utterance}\nDialogue Act:"
    return prompt

def gpt3_predict(prompt):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
            max_tokens=10
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        print("⚠️ OpenAI API Error:", e)
        return "ERROR"



!wget https://github.com/zihaohe123/speak-turn-emb-dialog-act-clf/raw/master/data.zip
!unzip data.zip


import pandas as pd

train_df = pd.read_csv("data/mrda/train.csv")



import openai
import pandas as pd
import random

# ⛔ Replace with your real OpenAI key
openai.api_key = "OPEN AI KEY"

def create_prompt(examples, test_utterance):
    prompt = "Classify the dialogue act of each utterance.\n\n"
    for ex in examples:
        prompt += f"Utterance: {ex['text']}\nDialogue Act: {ex['act']}\n\n"
    prompt += f"Utterance: {test_utterance}\nDialogue Act:"
    return prompt

def gpt3_predict(prompt):
    try:
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo",
            messages=[{"role": "user", "content": prompt}],
            temperature=0.0,
            max_tokens=10
        )
        return response['choices'][0]['message']['content'].strip()
    except Exception as e:
        print("⚠️ OpenAI API Error:", e)
        return "ERROR"

def load_dataset_local(dataset_name):
    train_path = f"data/{dataset_name}/train.csv"
    test_path = f"data/{dataset_name}/test.csv"

    train_df = pd.read_csv(train_path)
    test_df = pd.read_csv(test_path)

    train_data = train_df.to_dict(orient="records")
    test_data = test_df.to_dict(orient="records")

    print(f"✅ Loaded {len(train_data)} train and {len(test_data)} test samples from {dataset_name.upper()}")
    return train_data, test_data

def evaluate_dataset(dataset_name, k=5, test_samples=10):
    print(f"\n=== Evaluating {dataset_name.upper()} ===")
    train_data, test_data = load_dataset_local(dataset_name)

    correct = 0
    random.seed(42)

    for i in range(test_samples):
        few_shot_examples = random.sample(train_data, k)
        test_example = test_data[i]
        prompt = create_prompt(few_shot_examples, test_example['text'])
        prediction = gpt3_predict(prompt)

        print(f"[{i+1}] Predicted: {prediction} | Actual: {test_example['act']}")
        if str(prediction).lower().strip() == str(test_example['act']).lower().strip():

            correct += 1

    accuracy = correct / test_samples
    print(f"\n✅ Accuracy on {test_samples} samples from {dataset_name.upper()}: {accuracy:.2f}")

evaluate_dataset("mrda", k=5, test_samples=20)
evaluate_dataset("swda", k=5, test_samples=20)
evaluate_dataset("dyda", k=5, test_samples=20)