{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kwiUHs_F3iNf",
        "outputId": "0c6fbc95-d7fc-43bd-a581-7259b1e4be46"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.6.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai) (3.11.15)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Collecting fsspec<=2025.3.0,>=2023.1.0 (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets)\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai) (1.20.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.24.0->datasets) (4.13.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai) (2025.4.26)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "timm 1.0.15 requires torchvision, which is not installed.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2025.3.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2025.3.0\n"
          ]
        }
      ],
      "source": [
        "!pip install openai datasets\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSIdinESK5vo",
        "outputId": "20efabc2-5ea4-42ed-9d99-bb74d08bcb93"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai==0.28 in /usr/local/lib/python3.11/dist-packages (0.28.0)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install openai==0.28\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W9fxqQWv8fFz",
        "outputId": "af2b8528-2827-4329-f160-ecadf46ebae9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: openai in /usr/local/lib/python3.11/dist-packages (1.76.2)\n",
            "Collecting openai\n",
            "  Downloading openai-1.77.0-py3-none-any.whl.metadata (25 kB)\n",
            "Collecting datasets\n",
            "  Using cached datasets-3.6.0-py3-none-any.whl.metadata (19 kB)\n",
            "Collecting fsspec==2025.3.0\n",
            "  Using cached fsspec-2025.3.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.11/dist-packages (from openai) (4.9.0)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/local/lib/python3.11/dist-packages (from openai) (1.9.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.28.1)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from openai) (0.9.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.11/dist-packages (from openai) (2.11.4)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.11/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.11/dist-packages (from openai) (4.67.1)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.11 in /usr/local/lib/python3.11/dist-packages (from openai) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.18.0)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.0.2)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (18.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: huggingface-hub>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.30.2)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.11/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (3.11.15)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (2025.4.26)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.11/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.9)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.11/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.16.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /usr/local/lib/python3.11/dist-packages (from pydantic<3,>=1.9.0->openai) (0.4.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.4.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.2)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<=2025.3.0,>=2023.1.0->datasets) (1.20.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n",
            "Using cached fsspec-2025.3.0-py3-none-any.whl (193 kB)\n",
            "Downloading openai-1.77.0-py3-none-any.whl (662 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m662.0/662.0 kB\u001b[0m \u001b[31m13.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hUsing cached datasets-3.6.0-py3-none-any.whl (491 kB)\n",
            "Installing collected packages: fsspec, openai, datasets\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.76.2\n",
            "    Uninstalling openai-1.76.2:\n",
            "      Successfully uninstalled openai-1.76.2\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "bigframes 2.1.0 requires gcsfs>=2023.3.0, which is not installed.\n",
            "timm 1.0.15 requires torch, which is not installed.\n",
            "timm 1.0.15 requires torchvision, which is not installed.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed datasets-3.6.0 fsspec-2025.3.0 openai-1.77.0\n"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade openai datasets fsspec==2025.3.0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1Df5kKoF617w",
        "outputId": "b55d349d-054c-46b0-d28c-59c39d20d7ab"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: torch==2.5.0 in /usr/local/lib/python3.11/dist-packages (2.5.0)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (9.1.0.70)\n",
            "Collecting fsspec==2025.3.2\n",
            "  Using cached fsspec-2025.3.2-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: gcsfs==2025.3.2 in /usr/local/lib/python3.11/dist-packages (2025.3.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.6)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (12.4.127)\n",
            "Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (3.1.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch==2.5.0) (1.13.1)\n",
            "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.2) (3.11.15)\n",
            "Requirement already satisfied: decorator>4.1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.2) (4.4.2)\n",
            "Requirement already satisfied: google-auth>=1.2 in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.2) (2.38.0)\n",
            "Requirement already satisfied: google-auth-oauthlib in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.2) (1.2.2)\n",
            "Requirement already satisfied: google-cloud-storage in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.2) (2.19.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from gcsfs==2025.3.2) (2.32.3)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch==2.5.0) (1.3.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.2) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.2) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.2) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.2) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.2) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.2) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->gcsfs==2025.3.2) (1.20.0)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2025.3.2) (5.5.2)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2025.3.2) (0.4.2)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.11/dist-packages (from google-auth>=1.2->gcsfs==2025.3.2) (4.9.1)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from google-auth-oauthlib->gcsfs==2025.3.2) (2.0.0)\n",
            "Requirement already satisfied: google-api-core<3.0.0dev,>=2.15.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2025.3.2) (2.24.2)\n",
            "Requirement already satisfied: google-cloud-core<3.0dev,>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2025.3.2) (2.4.3)\n",
            "Requirement already satisfied: google-resumable-media>=2.7.2 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2025.3.2) (2.7.2)\n",
            "Requirement already satisfied: google-crc32c<2.0dev,>=1.0 in /usr/local/lib/python3.11/dist-packages (from google-cloud-storage->gcsfs==2025.3.2) (1.7.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2025.3.2) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2025.3.2) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2025.3.2) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->gcsfs==2025.3.2) (2025.4.26)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch==2.5.0) (3.0.2)\n",
            "Requirement already satisfied: googleapis-common-protos<2.0.0,>=1.56.2 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2025.3.2) (1.70.0)\n",
            "Requirement already satisfied: protobuf!=3.20.0,!=3.20.1,!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<7.0.0,>=3.19.5 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2025.3.2) (5.29.4)\n",
            "Requirement already satisfied: proto-plus<2.0.0,>=1.22.3 in /usr/local/lib/python3.11/dist-packages (from google-api-core<3.0.0dev,>=2.15.0->google-cloud-storage->gcsfs==2025.3.2) (1.26.1)\n",
            "Requirement already satisfied: pyasn1<0.7.0,>=0.6.1 in /usr/local/lib/python3.11/dist-packages (from pyasn1-modules>=0.2.1->google-auth>=1.2->gcsfs==2025.3.2) (0.6.1)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.11/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib->gcsfs==2025.3.2) (3.2.2)\n",
            "Using cached fsspec-2025.3.2-py3-none-any.whl (194 kB)\n",
            "Installing collected packages: fsspec\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.0\n",
            "    Uninstalling fsspec-2025.3.0:\n",
            "      Successfully uninstalled fsspec-2025.3.0\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "fastai 2.7.19 requires torchvision>=0.11, which is not installed.\n",
            "timm 1.0.15 requires torchvision, which is not installed.\n",
            "datasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed fsspec-2025.3.2\n"
          ]
        }
      ],
      "source": [
        "!pip install \"torch==2.5.0\" \"nvidia-cudnn-cu12==9.1.0.70\" \"fsspec==2025.3.2\" \"gcsfs==2025.3.2\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "4VOOHErfAYam"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "from datasets import load_dataset\n",
        "import random\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "BL2oK4u_32p3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BvkQOIfJ4siC"
      },
      "outputs": [],
      "source": [
        "openai.api_key =\"OPEN AI KEY\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "PLGVxFNbA89l"
      },
      "outputs": [],
      "source": [
        "def create_prompt(examples, test_utterance):\n",
        "    prompt = \"Classify the dialogue act of each utterance.\\n\\n\"\n",
        "    for ex in examples:\n",
        "        prompt += f\"Utterance: {ex['text']}\\nDialogue Act: {ex['act']}\\n\\n\"\n",
        "    prompt += f\"Utterance: {test_utterance}\\nDialogue Act:\"\n",
        "    return prompt\n",
        "\n",
        "def gpt3_predict(prompt):\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.0,\n",
        "            max_tokens=10\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ OpenAI API Error:\", e)\n",
        "        return \"ERROR\"\n",
        "\n",
        "def load_json_dataset(dataset_name):\n",
        "    import requests\n",
        "    import json\n",
        "\n",
        "    base_url = f\"https://raw.githubusercontent.com/zihaohe123/speak-turn-emb-dialog-act-clf/master/data/{dataset_name}\"\n",
        "    train_url = f\"{base_url}/train.json\"\n",
        "    test_url = f\"{base_url}/test.json\"\n",
        "\n",
        "    def load_json_lines(url):\n",
        "        response = requests.get(url)\n",
        "        lines = response.text.strip().split('\\n')\n",
        "        return [json.loads(line) for line in lines if line.strip()]\n",
        "\n",
        "    train_data = load_json_lines(train_url)\n",
        "    test_data = load_json_lines(test_url)\n",
        "\n",
        "    return train_data, test_data\n",
        "\n",
        "\n",
        "def evaluate_dataset(dataset_name, k=5, test_samples=10):\n",
        "    print(f\"\\n=== Evaluating {dataset_name.upper()} ===\")\n",
        "    train_data, test_data = load_json_dataset(dataset_name)\n",
        "    random.seed(42)\n",
        "    correct = 0\n",
        "\n",
        "    for i in range(test_samples):\n",
        "        few_shot_examples = random.sample(train_data, k)\n",
        "        test_example = test_data[i]\n",
        "        prompt = create_prompt(few_shot_examples, test_example['text'])\n",
        "        prediction = gpt3_predict(prompt)\n",
        "        print(f\"[{i+1}] Predicted: {prediction} | Actual: {test_example['act']}\")\n",
        "        if prediction.lower().strip() == test_example['act'].lower().strip():\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / test_samples\n",
        "    print(f\"\\n✅ Accuracy on {test_samples} samples from {dataset_name.upper()}: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD0u02g1Boly",
        "outputId": "9c90375c-bf5e-4c35-8d42-28b9f67acd04"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "--2025-05-07 23:56:23--  https://github.com/zihaohe123/speak-turn-emb-dialog-act-clf/raw/master/data.zip\n",
            "Resolving github.com (github.com)... 140.82.112.3\n",
            "Connecting to github.com (github.com)|140.82.112.3|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://raw.githubusercontent.com/zihaohe123/speak-turn-emb-dialog-act-clf/master/data.zip [following]\n",
            "--2025-05-07 23:56:24--  https://raw.githubusercontent.com/zihaohe123/speak-turn-emb-dialog-act-clf/master/data.zip\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7637050 (7.3M) [application/zip]\n",
            "Saving to: ‘data.zip.2’\n",
            "\n",
            "data.zip.2          100%[===================>]   7.28M  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-05-07 23:56:24 (75.0 MB/s) - ‘data.zip.2’ saved [7637050/7637050]\n",
            "\n",
            "Archive:  data.zip\n",
            "replace __MACOSX/._data? [y]es, [n]o, [A]ll, [N]one, [r]ename: A\n",
            "  inflating: __MACOSX/._data         \n",
            "  inflating: __MACOSX/data/._mrda    \n",
            "  inflating: __MACOSX/data/._swda    \n",
            "  inflating: __MACOSX/data/._dyda    \n",
            "  inflating: data/mrda/train.csv     \n",
            "  inflating: __MACOSX/data/mrda/._train.csv  \n",
            "  inflating: data/mrda/val.csv       \n",
            "  inflating: __MACOSX/data/mrda/._val.csv  \n",
            "  inflating: data/mrda/test.csv      \n",
            "  inflating: __MACOSX/data/mrda/._test.csv  \n",
            "  inflating: data/swda/test.csv      \n",
            "  inflating: __MACOSX/data/swda/._test.csv  \n",
            "  inflating: data/swda/train.csv     \n",
            "  inflating: __MACOSX/data/swda/._train.csv  \n",
            "  inflating: data/swda/val.csv       \n",
            "  inflating: __MACOSX/data/swda/._val.csv  \n",
            "  inflating: data/dyda/val.csv       \n",
            "  inflating: __MACOSX/data/dyda/._val.csv  \n",
            "  inflating: data/dyda/test.csv      \n",
            "  inflating: __MACOSX/data/dyda/._test.csv  \n",
            "  inflating: data/dyda/train.csv     \n",
            "  inflating: __MACOSX/data/dyda/._train.csv  \n"
          ]
        }
      ],
      "source": [
        "def create_prompt(examples, test_utterance):\n",
        "    prompt = \"Classify the dialogue act of each utterance.\\n\\n\"\n",
        "    for ex in examples:\n",
        "        prompt += f\"Utterance: {ex['text']}\\nDialogue Act: {ex['act']}\\n\\n\"\n",
        "    prompt += f\"Utterance: {test_utterance}\\nDialogue Act:\"\n",
        "    return prompt\n",
        "\n",
        "def gpt3_predict(prompt):\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.0,\n",
        "            max_tokens=10\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ OpenAI API Error:\", e)\n",
        "        return \"ERROR\"\n",
        "\n",
        "\n",
        "\n",
        "!wget https://github.com/zihaohe123/speak-turn-emb-dialog-act-clf/raw/master/data.zip\n",
        "!unzip data.zip\n",
        "\n",
        "\n",
        "import pandas as pd\n",
        "\n",
        "train_df = pd.read_csv(\"data/mrda/train.csv\")\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 529
        },
        "id": "wuS4aMLmKnMW",
        "outputId": "3b7b8efc-5a67-441e-ac04-17e80a4bde78"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai==0.28\n",
            "  Downloading openai-0.28.0-py3-none-any.whl.metadata (13 kB)\n",
            "Requirement already satisfied: requests>=2.20 in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (2.32.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (4.67.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from openai==0.28) (3.11.15)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2.4.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.20->openai==0.28) (2025.4.26)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.6.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (6.4.3)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->openai==0.28) (1.20.0)\n",
            "Downloading openai-0.28.0-py3-none-any.whl (76 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/76.5 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m76.5/76.5 kB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: openai\n",
            "  Attempting uninstall: openai\n",
            "    Found existing installation: openai 1.77.0\n",
            "    Uninstalling openai-1.77.0:\n",
            "      Successfully uninstalled openai-1.77.0\n",
            "Successfully installed openai-0.28.0\n"
          ]
        },
        {
          "data": {
            "application/vnd.colab-display-data+json": {
              "id": "a7c98602b66f45118d059d7a3107f975",
              "pip_warning": {
                "packages": [
                  "openai"
                ]
              }
            }
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qjSx7mO4B102"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# ⛔ Replace with your real OpenAI key\n",
        "openai.api_key = \"OPEN AI KEY\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "kJyb3ix-I5l8"
      },
      "outputs": [],
      "source": [
        "def create_prompt(examples, test_utterance):\n",
        "    prompt = \"Classify the dialogue act of each utterance.\\n\\n\"\n",
        "    for ex in examples:\n",
        "        prompt += f\"Utterance: {ex['text']}\\nDialogue Act: {ex['act']}\\n\\n\"\n",
        "    prompt += f\"Utterance: {test_utterance}\\nDialogue Act:\"\n",
        "    return prompt\n",
        "\n",
        "def gpt3_predict(prompt):\n",
        "    try:\n",
        "        response = openai.ChatCompletion.create(\n",
        "            model=\"gpt-3.5-turbo\",\n",
        "            messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "            temperature=0.0,\n",
        "            max_tokens=10\n",
        "        )\n",
        "        return response['choices'][0]['message']['content'].strip()\n",
        "    except Exception as e:\n",
        "        print(\"⚠️ OpenAI API Error:\", e)\n",
        "        return \"ERROR\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "2f6f-NOSKGTp"
      },
      "outputs": [],
      "source": [
        "def load_dataset_local(dataset_name):\n",
        "    train_path = f\"data/{dataset_name}/train.csv\"\n",
        "    test_path = f\"data/{dataset_name}/test.csv\"\n",
        "\n",
        "    train_df = pd.read_csv(train_path)\n",
        "    test_df = pd.read_csv(test_path)\n",
        "\n",
        "    train_data = train_df.to_dict(orient=\"records\")\n",
        "    test_data = test_df.to_dict(orient=\"records\")\n",
        "\n",
        "    print(f\"✅ Loaded {len(train_data)} train and {len(test_data)} test samples from {dataset_name.upper()}\")\n",
        "    return train_data, test_data\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "B6lzdFeTCKMh"
      },
      "outputs": [],
      "source": [
        "def evaluate_dataset(dataset_name, k=5, test_samples=10):\n",
        "    print(f\"\\n=== Evaluating {dataset_name.upper()} ===\")\n",
        "    train_data, test_data = load_dataset_local(dataset_name)\n",
        "\n",
        "    correct = 0\n",
        "    random.seed(42)\n",
        "\n",
        "    for i in range(test_samples):\n",
        "        few_shot_examples = random.sample(train_data, k)\n",
        "        test_example = test_data[i]\n",
        "        prompt = create_prompt(few_shot_examples, test_example['text'])\n",
        "        prediction = gpt3_predict(prompt)\n",
        "\n",
        "        print(f\"[{i+1}] Predicted: {prediction} | Actual: {test_example['act']}\")\n",
        "        if str(prediction).lower().strip() == str(test_example['act']).lower().strip():\n",
        "\n",
        "            correct += 1\n",
        "\n",
        "    accuracy = correct / test_samples\n",
        "    print(f\"\\n✅ Accuracy on {test_samples} samples from {dataset_name.upper()}: {accuracy:.2f}\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pZcQGda6CNzP",
        "outputId": "230d294a-4ccf-4762-9c6f-d03cceade810"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "=== Evaluating MRDA ===\n",
            "✅ Loaded 75016 train and 15053 test samples from MRDA\n",
            "[1] Predicted: 2 | Actual: 0\n",
            "[2] Predicted: 0 | Actual: 0\n",
            "[3] Predicted: 0 | Actual: 0\n",
            "[4] Predicted: 1 | Actual: 3\n",
            "[5] Predicted: 0 | Actual: 0\n",
            "[6] Predicted: 3 | Actual: 3\n",
            "[7] Predicted: Statement | Actual: 2\n",
            "[8] Predicted: Statement | Actual: 0\n",
            "[9] Predicted: 1 | Actual: 0\n",
            "[10] Predicted: 1 | Actual: 0\n",
            "[11] Predicted: 3 | Actual: 0\n",
            "[12] Predicted: 1 | Actual: 0\n",
            "[13] Predicted: 0 | Actual: 0\n",
            "[14] Predicted: 1 | Actual: 0\n",
            "[15] Predicted: 3 | Actual: 0\n",
            "[16] Predicted: 1 | Actual: 0\n",
            "[17] Predicted: 1 | Actual: 2\n",
            "[18] Predicted: 0 | Actual: 0\n",
            "[19] Predicted: 3 | Actual: 4\n",
            "[20] Predicted: 0 | Actual: 0\n",
            "\n",
            "✅ Accuracy on 20 samples from MRDA: 0.35\n",
            "\n",
            "=== Evaluating SWDA ===\n",
            "✅ Loaded 193325 train and 4514 test samples from SWDA\n",
            "[1] Predicted: 5 | Actual: 8\n",
            "[2] Predicted: 35 | Actual: 8\n",
            "[3] Predicted: 8 | Actual: 35\n",
            "[4] Predicted: 11 | Actual: 6\n",
            "[5] Predicted: 8 | Actual: 42\n",
            "[6] Predicted: 9 | Actual: 6\n",
            "[7] Predicted: 35 | Actual: 35\n",
            "[8] Predicted: 6 | Actual: 6\n",
            "[9] Predicted: 8 | Actual: 42\n",
            "[10] Predicted: 8 | Actual: 6\n",
            "[11] Predicted: 1 | Actual: 42\n",
            "[12] Predicted: 6 | Actual: 6\n",
            "[13] Predicted: 31 | Actual: 35\n",
            "[14] Predicted: 27 | Actual: 6\n",
            "[15] Predicted: 8 | Actual: 35\n",
            "[16] Predicted: 6 | Actual: 6\n",
            "[17] Predicted: 42 | Actual: 42\n",
            "[18] Predicted: 6 | Actual: 6\n",
            "[19] Predicted: 8 | Actual: 42\n",
            "[20] Predicted: 6 | Actual: 6\n",
            "\n",
            "✅ Accuracy on 20 samples from SWDA: 0.35\n",
            "\n",
            "=== Evaluating DYDA ===\n",
            "✅ Loaded 87170 train and 7740 test samples from DYDA\n",
            "[1] Predicted: 2 | Actual: 2\n",
            "[2] Predicted: 1 | Actual: 1\n",
            "[3] Predicted: 1 | Actual: 2\n",
            "[4] Predicted: 1 | Actual: 3\n",
            "[5] Predicted: 1 | Actual: 2\n",
            "[6] Predicted: 0 | Actual: 3\n",
            "[7] Predicted: 2 | Actual: 2\n",
            "[8] Predicted: 2 | Actual: 1\n",
            "[9] Predicted: 2 | Actual: 2\n",
            "[10] Predicted: 0 | Actual: 3\n",
            "[11] Predicted: 1 | Actual: 1\n",
            "[12] Predicted: 2 | Actual: 2\n",
            "[13] Predicted: 0 | Actual: 0\n",
            "[14] Predicted: 1 | Actual: 1\n",
            "[15] Predicted: 2 | Actual: 0\n",
            "[16] Predicted: 0 | Actual: 0\n",
            "[17] Predicted: 0 | Actual: 0\n",
            "[18] Predicted: 1 | Actual: 1\n",
            "[19] Predicted: 0 | Actual: 0\n",
            "[20] Predicted: 0 | Actual: 1\n",
            "\n",
            "✅ Accuracy on 20 samples from DYDA: 0.60\n"
          ]
        }
      ],
      "source": [
        "evaluate_dataset(\"mrda\", k=5, test_samples=20)\n",
        "evaluate_dataset(\"swda\", k=5, test_samples=20)\n",
        "evaluate_dataset(\"dyda\", k=5, test_samples=20)\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "A100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
